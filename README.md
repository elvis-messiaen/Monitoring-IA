# Monitoring-IA

A comprehensive Machine Learning monitoring solution that combines Titanic prediction models with real-time monitoring using Prometheus, Grafana, and Docker.

## ğŸ“‹ Overview

This project implements a complete ML monitoring pipeline for a Titanic survival prediction model. It includes:
- FastAPI-based REST API for ML predictions
- Real-time monitoring and metrics collection with Prometheus
- Interactive dashboards with Grafana
- Container orchestration with Docker Compose
- Container-level monitoring with cAdvisor

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Grafana   â”‚    â”‚ Prometheus  â”‚    â”‚  FastAPI    â”‚
â”‚   (Dashboards)   â”‚  (Metrics)   â”‚  â”‚   (API)     â”‚
â”‚   Port 3000 â”‚    â”‚   Port 9090 â”‚    â”‚   Port 8000 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚                   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  cAdvisor   â”‚
                    â”‚(Container   â”‚
                    â”‚ Monitoring) â”‚
                    â”‚   Port 8080 â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Docker and Docker Compose
- Git
- Python 3.11+ (pour dÃ©veloppement local)

### Installation et dÃ©marrage

1. **Cloner le repository**
   ```bash
   git clone https://github.com/elvis-messiaen/Monitoring-IA.git
   cd Monitoring-IA
   ```

2. **DÃ©marrer tous les services**
   ```bash
   docker-compose up -d --build
   ```

3. **VÃ©rifier que les services fonctionnent**
   ```bash
   # VÃ©rifier l'Ã©tat des conteneurs
   docker-compose ps

   # Tester l'API
   curl http://localhost:8000/health

   # Tester une prÃ©diction
   curl -X POST "http://localhost:8000/monitoring/test/prediction?model_version=v1.0&prediction_class=survived&confidence=0.85"

   # Consulter les mÃ©triques Prometheus
   curl http://localhost:8000/metrics
   ```

### Points d'accÃ¨s

- **API Documentation**: http://localhost:8000/docs
- **API Health**: http://localhost:8000/health
- **Prometheus Metrics**: http://localhost:8000/metrics
- **Grafana Dashboard**: http://localhost:3000 (admin/admin)
- **Prometheus**: http://localhost:9090
- **cAdvisor**: http://localhost:8080

### GÃ©nÃ©rer un rapport Evidently

```bash
# Installer les dÃ©pendances (si dÃ©veloppement local)
pip install -r requirements.txt

# GÃ©nÃ©rer un rapport de drift
python scripts/generer_rapport_test.py

# Ouvrir le rapport
open reports/drift_report_test.html
```

## ğŸ“ Project Structure

```
Monitoring-IA/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py              # FastAPI application avec endpoints de monitoring
â”‚   â”œâ”€â”€ metrics/
â”‚   â”‚   â”œâ”€â”€ __init__.py      # Exposition des fonctions de monitoring
â”‚   â”‚   â””â”€â”€ monitoring.py    # MÃ©triques Prometheus + Rapports Evidently
â”‚   â”œâ”€â”€ config.py            # Configuration
â”‚   â”œâ”€â”€ models.py            # ML models definitions
â”‚   â”œâ”€â”€ predict.py           # Prediction endpoints
â”‚   â””â”€â”€ Dockerfile           # Docker configuration pour l'API
â”œâ”€â”€ grafana/
â”‚   â”œâ”€â”€ datasources/
â”‚   â”‚   â””â”€â”€ prometheus.yml   # Configuration datasource Grafana
â”‚   â””â”€â”€ dashboards/          # DÃ©finitions des dashboards
â”œâ”€â”€ prometheus/
â”‚   â””â”€â”€ prometheus.yml       # Configuration scraping Prometheus
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb  # Exploration des donnÃ©es
â”‚   â””â”€â”€ 02_model_training.ipynb    # EntraÃ®nement du modÃ¨le
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/Titanic-Dataset.csv   # Dataset Titanic brut
â”‚   â””â”€â”€ titanic_cleaned_dataset.csv # Dataset nettoyÃ©
â”œâ”€â”€ models/                # ArtÃ©facts ML sauvegardÃ©s
â”œâ”€â”€ reports/               # Rapports Evidently gÃ©nÃ©rÃ©s (HTML)
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ generer_rapport_test.py    # Script de gÃ©nÃ©ration de rapports
â”œâ”€â”€ tests/                 # Suite de tests
â”œâ”€â”€ requirements.txt       # DÃ©pendances Python
â”œâ”€â”€ docker-compose.yml     # Orchestration Docker
â”œâ”€â”€ CLAUDE.md             # Guide pour Claude Code
â”œâ”€â”€ tempo.md              # Guide de dÃ©marrage rapide
â””â”€â”€ README.md             # Ce fichier
```

## ğŸ”§ Configuration

### API Configuration

The FastAPI application is configured with:
- **Port**: 8000
- **Health check**: `/health` endpoint
- **Metrics**: `/metrics` endpoint (Prometheus integration)
- **Environment**: Production mode

### Monitoring Stack

#### Prometheus
- **Scraping interval**: 15 seconds
- **Targets**:
  - API metrics: `api:8000/metrics`
  - Prometheus self-monitoring: `prometheus:9090`
  - cAdvisor containers metrics: `cadvisor:8080`

#### Grafana
- **Admin credentials**: admin/admin
- **Data sources**:
  - Prometheus (default)
  - cAdvisor
  - Titanic-API

#### cAdvisor
- **Container monitoring**: Resource usage, performance metrics
- **Docker integration**: Automatic container discovery

## ğŸ“Š FonctionnalitÃ©s disponibles

### API Endpoints

| Endpoint | MÃ©thode | Description |
|----------|---------|-------------|
| `/` | GET | Informations sur l'API |
| `/health` | GET | Healthcheck Docker |
| `/metrics` | GET | MÃ©triques Prometheus |
| `/docs` | GET | Documentation Swagger interactive |
| `/monitoring/stats` | GET | Statistiques de monitoring |
| `/monitoring/test/prediction` | POST | Test d'enregistrement de prÃ©diction |
| `/monitoring/test/accuracy` | POST | Test de mise Ã  jour d'accuracy |

### MÃ©triques Prometheus personnalisÃ©es

Toutes les mÃ©triques ML sont disponibles via `/metrics`:

- `ml_predictions_total` - Compteur de prÃ©dictions par version et classe
- `ml_prediction_latency_seconds` - Histogramme de latence des prÃ©dictions
- `ml_prediction_errors_total` - Compteur d'erreurs par type
- `ml_prediction_confidence` - Gauge de confiance moyenne par classe
- `ml_prediction_confidence_summary` - Statistiques de confiance
- `ml_data_drift_detected_total` - Compteur de drift dÃ©tectÃ© par feature
- `ml_data_drift_score` - Score de drift global (0-1)
- `ml_model_accuracy` - PrÃ©cision actuelle du modÃ¨le
- `ml_monitoring_requests_total` - Compteur de requÃªtes de monitoring

### Rapports Evidently

GÃ©nÃ©ration de rapports HTML interactifs pour:
- **Classification Performance**: MÃ©triques de performance du modÃ¨le
- **Data Drift Detection**: DÃ©tection de dÃ©rive des donnÃ©es
- **Rapports combinÃ©s**: Classification + Drift

Les rapports sont sauvegardÃ©s dans `reports/` et s'ouvrent dans le navigateur.

### Dashboards

- **System Overview**: SantÃ© et performance globale du systÃ¨me
- **API Performance**: MÃ©triques de requÃªtes et temps de rÃ©ponse
- **Container Monitoring**: Utilisation des ressources par conteneur
- **ML Model Metrics**: Performance du modÃ¨le et drift (via Evidently)

## ğŸ³ Docker Services

### API Service
```yaml
- Image: Custom build from api/Dockerfile
- Ports: 8000:8000
- Volumes: ./models, ./reports, ./data
- Health check: HTTP health endpoint
- Restart: unless-stopped
```

### Prometheus Service
```yaml
- Image: prom/prometheus:latest
- Ports: 9090:9090
- Volume: Custom prometheus.yml
- Data persistence: prometheus_data volume
- Restart: unless-stopped
```

### Grafana Service
```yaml
- Image: grafana/grafana:latest
- Ports: 3000:3000
- Volumes: Dashboard and datasource provisioning
- Environment: Admin password configuration
- Restart: unless-stopped
```

### cAdvisor Service
```yaml
- Image: gcr.io/cadvisor/cadvisor:latest
- Ports: 8080:8080
- Volumes: System mounts for container monitoring
- Restart: unless-stopped
```

## ğŸ“š Dependencies

### Core Dependencies
- **FastAPI**: Web framework for APIs
- **Uvicorn**: ASGI server
- **Pydantic**: Data validation

### Machine Learning
- **scikit-learn**: ML algorithms
- **pandas**: Data manipulation
- **numpy**: Numerical operations
- **seaborn**: Data visualization
- **matplotlib**: Plotting

### Monitoring
- **prometheus-client**: Prometheus metrics client
- **prometheus-fastapi-instrumentator**: FastAPI integration
- **evidently**: ML monitoring and drift detection

### Utilities
- **python-multipart**: File uploads
- **python-dotenv**: Environment variables
- **loguru**: Logging
- **pytest**: Testing framework

## ğŸ” Development

### Running Tests
```bash
pytest tests/
```

### Development Mode
```bash
# Install dependencies
pip install -r requirements.txt

# Run API locally
uvicorn api.main:app --reload --host 0.0.0.0 --port 8000
```

### Monitoring Development

```bash
# Voir les mÃ©triques Prometheus
curl http://localhost:9090/metrics

# Voir les mÃ©triques API personnalisÃ©es
curl http://localhost:8000/metrics

# GÃ©nÃ©rer un rapport Evidently
python scripts/generer_rapport_test.py

# Tester l'enregistrement de prÃ©dictions
curl -X POST "http://localhost:8000/monitoring/test/prediction?model_version=v1.0&prediction_class=survived&confidence=0.85"

# Tester la mise Ã  jour d'accuracy
curl -X POST "http://localhost:8000/monitoring/test/accuracy?model_version=v1.0&accuracy=0.82"
```

### Utiliser les fonctions de monitoring dans votre code

```python
from api.metrics import (
    enregistrer_prediction,
    enregistrer_erreur,
    mettre_a_jour_accuracy,
    generer_rapport_drift,
    generer_rapport_complet
)

# Enregistrer une prÃ©diction
enregistrer_prediction(
    model_version="v1.0",
    prediction_class="survived",
    confidence=0.85,
    latency=0.023
)

# GÃ©nÃ©rer un rapport de drift
import pandas as pd

reference_data = pd.read_csv('data/titanic_cleaned_dataset.csv')
current_data = pd.read_csv('data/new_data.csv')

rapport = generer_rapport_drift(
    reference_data=reference_data,
    current_data=current_data,
    output_path='reports/drift_report.html'
)
```

## ğŸ“ˆ Future Enhancements

- **ML Model Integration**: Complete Titanic prediction model
- **Custom Metrics**: Business-specific KPIs
- **Alerting**: Automated notifications for anomalies
- **Model Versioning**: A/B testing and model comparison
- **Data Quality Monitoring**: Input data validation
- **Model Drift Detection**: Automated performance tracking
- **Security Enhancements**: Authentication and authorization
- **Performance Optimization**: Caching and load balancing

## ğŸ› ï¸ Troubleshooting

### Common Issues

1. **Port conflicts**: Ensure ports 3000, 8000, 8080, 9090 are available
2. **Docker permissions**: Ensure user has Docker permissions
3. **Resource limits**: Monitor system resources with `docker stats`

### Logs

```bash
# View all logs
docker-compose logs

# View specific service logs
docker-compose logs api
docker-compose logs prometheus
docker-compose logs grafana
```

### Reset Services

```bash
# Stop and remove all containers
docker-compose down

# Remove volumes (note: this deletes all data)
docker-compose down -v

# Rebuild and restart
docker-compose up -d --build
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ“ Support

For questions and support:
- Create an issue in the GitHub repository
- Check the documentation at `/docs` endpoint
- Review Grafana dashboards for system insights

---

**Note**: This is an ML monitoring project focusing on infrastructure setup. The actual machine learning model and advanced monitoring features are currently being developed.